{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00000-18d4f713-702d-4735-b48d-98253c9ff02d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 719,
    "execution_start": 1618690704816,
    "source_hash": "a3f40003",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9c642ee0dd05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspearmanr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from misc import data, c\n",
    "from torch import optim\n",
    "from scipy.stats import spearmanr\n",
    "from vae2 import VAE # import the last version\n",
    "\n",
    "def get_cor_ensamble(batch, mutants_values, model, ensambles = 512, rand = True):\n",
    "    model.eval()\n",
    "\n",
    "    mt_elbos, wt_elbos = 0, 0\n",
    "\n",
    "    for i in range(ensambles):\n",
    "        if i and (i % 2 == 0):\n",
    "            print(f\"\\tReached {i}/rand={rand}\", \" \"*32, end=\"\\r\")\n",
    "\n",
    "        elbos     = model.logp(batch, rand=rand).detach().cpu()\n",
    "        wt_elbos += elbos[0]\n",
    "        mt_elbos += elbos[1:]\n",
    "\n",
    "    print()\n",
    "\n",
    "    diffs  = (mt_elbos / ensambles) - (wt_elbos / ensambles)\n",
    "    cor, _ = spearmanr(mutants_values, diffs)\n",
    "    \n",
    "    return cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-5061a833-e627-4491-89ad-a2fc29b50974",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10982,
    "execution_start": 1618690705547,
    "source_hash": "3ab672",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing fasta 'data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105.a2m'\n",
      "Parsing labels 'data/BLAT_ECOLX_hmmerbit_plmc_n5_m30_f50_t0.2_r24-286_id100_b105_LABELS.a2m'\n",
      "Generating 8403 1-hot encodings\n",
      "Generating 8403 1-hot encodings. Took 0.793s torch.Size([8403, 23, 253])\n",
      "Generating 4807 1-hot encodings\n",
      "Generating 4807 1-hot encodings. Took 0.421s torch.Size([4807, 23, 253])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloader, df, mutants_tensor, mutants_df, neff = data(batch_size = 64, device=device)\n",
    "\n",
    "wildtype   = dataloader.dataset[0] # one-hot-encoded wildtype \n",
    "eval_batch = torch.cat([wildtype.unsqueeze(0), mutants_tensor.to(device)])\n",
    "\n",
    "args = {\n",
    "    'alphabet_len': dataloader.dataset[0].shape[0],\n",
    "    'seq_len':      dataloader.dataset[0].shape[1],\n",
    "    'neff':         neff\n",
    "}\n",
    "\n",
    "vae   = VAE(**args).to(device)\n",
    "opt   = optim.Adam(vae.parameters())\n",
    "\n",
    "stats = {\n",
    "    'rl': [],  # rl  = Reconstruction loss\n",
    "    'klz': [], # kl  = Kullback-Leibler divergence loss\n",
    "    'klp': [],  # KL divergence loss for parameters\n",
    "    'cor': []  # cor = Spearman correlation to experimentally measured \n",
    "    }          # protein fitness according to eq.1 from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-3d8c2837-712a-4412-b24c-70cd1c8685ca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1618690716536,
    "source_hash": "3b47c631",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=5819, out_features=64, bias=True)\n",
       "  (fc1h): Linear(in_features=64, out_features=30, bias=True)\n",
       "  (fc21): Linear(in_features=30, out_features=2, bias=True)\n",
       "  (fc22): Linear(in_features=30, out_features=2, bias=True)\n",
       "  (fc3): Linear(in_features=2, out_features=32, bias=False)\n",
       "  (fc3h): Linear(in_features=32, out_features=64, bias=False)\n",
       "  (W): Linear(in_features=16, out_features=16192, bias=False)\n",
       "  (C): Linear(in_features=23, out_features=16, bias=False)\n",
       "  (S): Linear(in_features=253, out_features=8, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-d5ea2a27-0480-48ca-830d-0587fffa8a01",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 430260,
    "execution_start": 1618690721481,
    "output_cleared": false,
    "source_hash": "3941e14",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReached 14/rand=True                                 \n",
      "\u001b[95mEPOCH 000 \u001b[94mRL=778.7021 \u001b[92mKLZ=0.1985 \u001b[96m|rho|=0.4288\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 001 \u001b[94mRL=748.3698 \u001b[92mKLZ=0.0257 \u001b[96m|rho|=0.4620\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 002 \u001b[94mRL=712.2460 \u001b[92mKLZ=0.0307 \u001b[96m|rho|=0.5206\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 003 \u001b[94mRL=670.7138 \u001b[92mKLZ=0.0251 \u001b[96m|rho|=0.5455\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 004 \u001b[94mRL=628.1255 \u001b[92mKLZ=0.0167 \u001b[96m|rho|=0.5637\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 005 \u001b[94mRL=589.5910 \u001b[92mKLZ=0.0115 \u001b[96m|rho|=0.5766\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 006 \u001b[94mRL=558.5648 \u001b[92mKLZ=0.0081 \u001b[96m|rho|=0.5817\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 007 \u001b[94mRL=538.0320 \u001b[92mKLZ=0.0061 \u001b[96m|rho|=0.5864\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 008 \u001b[94mRL=527.0403 \u001b[92mKLZ=0.0043 \u001b[96m|rho|=0.5911\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 009 \u001b[94mRL=519.9695 \u001b[92mKLZ=0.0040 \u001b[96m|rho|=0.5948\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 010 \u001b[94mRL=514.7305 \u001b[92mKLZ=0.0039 \u001b[96m|rho|=0.5973\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 011 \u001b[94mRL=511.7554 \u001b[92mKLZ=0.0042 \u001b[96m|rho|=0.5998\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 012 \u001b[94mRL=512.0990 \u001b[92mKLZ=0.0040 \u001b[96m|rho|=0.6011\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 013 \u001b[94mRL=509.3880 \u001b[92mKLZ=0.0047 \u001b[96m|rho|=0.6022\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 014 \u001b[94mRL=507.8127 \u001b[92mKLZ=0.0044 \u001b[96m|rho|=0.6027\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 015 \u001b[94mRL=507.8654 \u001b[92mKLZ=0.0049 \u001b[96m|rho|=0.6019\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 016 \u001b[94mRL=508.3556 \u001b[92mKLZ=0.0048 \u001b[96m|rho|=0.6021\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 017 \u001b[94mRL=507.3471 \u001b[92mKLZ=0.0052 \u001b[96m|rho|=0.6021\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 018 \u001b[94mRL=506.6234 \u001b[92mKLZ=0.0049 \u001b[96m|rho|=0.6028\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 019 \u001b[94mRL=507.4076 \u001b[92mKLZ=0.0055 \u001b[96m|rho|=0.6021\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 020 \u001b[94mRL=505.5530 \u001b[92mKLZ=0.0053 \u001b[96m|rho|=0.6018\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 021 \u001b[94mRL=505.8631 \u001b[92mKLZ=0.0052 \u001b[96m|rho|=0.6023\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 022 \u001b[94mRL=507.6688 \u001b[92mKLZ=0.0051 \u001b[96m|rho|=0.6004\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 023 \u001b[94mRL=505.5267 \u001b[92mKLZ=0.0056 \u001b[96m|rho|=0.6005\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 024 \u001b[94mRL=506.0650 \u001b[92mKLZ=0.0051 \u001b[96m|rho|=0.6019\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 025 \u001b[94mRL=504.9987 \u001b[92mKLZ=0.0051 \u001b[96m|rho|=0.6009\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 026 \u001b[94mRL=506.1947 \u001b[92mKLZ=0.0048 \u001b[96m|rho|=0.6005\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 027 \u001b[94mRL=506.0816 \u001b[92mKLZ=0.0046 \u001b[96m|rho|=0.5997\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 028 \u001b[94mRL=504.4375 \u001b[92mKLZ=0.0047 \u001b[96m|rho|=0.6010\u001b[0m\n",
      "\n",
      "\u001b[95mEPOCH 029 \u001b[94mRL=505.6914 \u001b[92mKLZ=0.0044 \u001b[96m|rho|=0.5995\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    # Unsupervised training on the MSA sequences.\n",
    "    # https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n",
    "    vae.train()\n",
    "    \n",
    "    epoch_losses = { 'rl': [], 'klp': [], 'klz': [] }\n",
    "    for batch in dataloader:\n",
    "        # https://discuss.pytorch.org/t/what-step-backward-and-zero-grad-do/33301/2\n",
    "        opt.zero_grad()\n",
    "        x_hat, mu, logvar  = vae(batch)\n",
    "        loss, rl, klz, klp = vae.loss(x_hat, batch, mu, logvar)\n",
    "        loss.mean().backward(retain_graph=True) # Stefan: Do we need 'retain_graph'? - ask yevgen \n",
    "        opt.step()\n",
    "        epoch_losses['rl'].append(rl.mean().item())\n",
    "        epoch_losses['klp'].append(klp.mean().item())\n",
    "        epoch_losses['klz'].append(klz.item())\n",
    "\n",
    "    # Evaluation on mutants\n",
    "    vae.eval()\n",
    "    # x_hat_eval, mu, logvar = vae(eval_batch, rep=False)\n",
    "    # elbos, _, _, _ = vae.loss(x_hat_eval, eval_batch, mu, logvar)\n",
    "    # elbos = vae.logp(eval_batch)\n",
    "    # diffs       = elbos[1:] - elbos[0] # log-ratio (first equation in the paper)\n",
    "    # cor, _      = spearmanr(mutants_df.value, diffs.detach().to('cpu'))\n",
    "    cor = get_cor_ensamble(eval_batch, mutants_df.value, vae, ensambles=16, rand=True)\n",
    "    \n",
    "    # Populate statistics \n",
    "    stats['rl'].append(np.mean(epoch_losses['rl']))\n",
    "    stats['klz'].append(np.mean(epoch_losses['klz']))\n",
    "    stats['klp'].append(np.mean(epoch_losses['klp']))\n",
    "    stats['cor'].append(np.abs(cor))\n",
    "\n",
    "    to_print = [\n",
    "        f\"{c.HEADER}EPOCH %03d\"          % epoch,\n",
    "        f\"{c.OKBLUE}RL=%4.4f\"            % stats['rl'][-1], # reconstrution loss\n",
    "        f\"{c.OKGREEN}KLZ=%4.4f\"          % stats['klz'][-1], # KL loss\n",
    "        f\"{c.OKCYAN}|rho|=%4.4f{c.ENDC}\" % stats['cor'][-1] # correlation (we want to max this value)\n",
    "    ]\n",
    "    print(\" \".join(to_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-00c14cca-5c81-4b9f-af18-d3179d5806ed",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1618691660466,
    "output_cleared": true,
    "source_hash": "bd0bf4d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'state_dict': vae.state_dict(), \n",
    "    'stats':      stats,\n",
    "    'args':       args,\n",
    "}, \"models/full_paper.model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-6a2d40dc-3847-4094-8468-89cd925b7768",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=35838f82-2ce6-4453-9bd2-2d87a43af151' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "38e9e71b-385a-4a4d-a676-9d1c1a59cc56",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
